{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import tree \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.float_format',lambda x: '%.4f' %x)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "train_data = pd.read_csv('data/trainingset.txt',header=None)\n",
    "test_data = pd.read_csv('data/queries.txt',header=None)\n",
    "#set column names for train_data\n",
    "train_data.columns = ['id','age','job','marital','education','default','balance','housing','loan','contact','day','month','duration','campaign','pdays','previous','poutcome','output']\n",
    "test_data.columns = ['id','age','job','marital','education','default','balance','housing','loan','contact','day','month','duration','campaign','pdays','previous','poutcome','output']\n",
    "\n",
    "#assign the datatypes to the columns\n",
    "train_data.age = train_data.age.astype('int64')\n",
    "train_data.job = train_data.job.astype('category')\n",
    "train_data.marital = train_data.marital.astype('category')\n",
    "train_data.education = train_data.education.astype('category')\n",
    "train_data.default = train_data.default.map({'yes':1,'no':0})\n",
    "train_data.balance = train_data.balance.astype('float64')\n",
    "train_data.housing = train_data.housing.map({'yes': 1, 'no': 0})\n",
    "train_data.loan = train_data.loan.map({'yes': 1, 'no': 0})\n",
    "train_data.contact = train_data.contact.map({'cellular': 0, 'telephone': 1, 'unknown': 2})\n",
    "train_data.day = train_data.day.astype('int64')\n",
    "train_data.month = train_data.month.astype('category')\n",
    "train_data.duration = train_data.duration.astype('int64')\n",
    "train_data.campaign = train_data.campaign.astype('int64')\n",
    "train_data.pdays = train_data.pdays.astype('int64')\n",
    "train_data.previous = train_data.previous.astype('int64')\n",
    "train_data.poutcome = train_data.poutcome.map({'failure': 0, 'success': 1, 'unknown': 2})\n",
    "train_data.output = train_data.output.map({'TypeA': 1, 'TypeB': 0})\n",
    "\n",
    "#assign the same datatypes to the columns of the test_data\n",
    "test_data.age = test_data.age.astype('int64')\n",
    "test_data.job = test_data.job.astype('category')\n",
    "test_data.marital = test_data.marital.astype('category')\n",
    "test_data.education = test_data.education.astype('category')\n",
    "test_data.default = test_data.default.map({'yes':1,'no':0})\n",
    "test_data.balance = test_data.balance.astype('float64')\n",
    "test_data.housing = test_data.housing.map({'yes': 1, 'no': 0})\n",
    "test_data.loan = test_data.loan.map({'yes': 1, 'no': 0})\n",
    "test_data.contact = test_data.contact.map({'cellular': 0, 'telephone': 1, 'unknown': 2})\n",
    "test_data.day = test_data.day.astype('int64')\n",
    "test_data.month = test_data.month.astype('category')\n",
    "test_data.duration = test_data.duration.astype('int64')\n",
    "test_data.campaign = test_data.campaign.astype('int64')\n",
    "test_data.pdays = test_data.pdays.astype('int64')\n",
    "test_data.previous = test_data.previous.astype('int64')\n",
    "test_data.poutcome = test_data.poutcome.map({'failure': 0, 'success': 1, 'unknown': 2})\n",
    "test_data.output = test_data.output.map({'TypeA': 1, 'TypeB': 0})\n",
    "\n",
    "#convert the catagorical variables to dummy variables\n",
    "train_data = pd.get_dummies(train_data, columns=['job','marital','education','default','housing','loan','contact','month','poutcome'],drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=['job','marital','education','default','housing','loan','contact','month','poutcome'],drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.9825246710526315\n",
      "Variance score: 0.9825246710526315\n",
      "Mean Absolute Error: 0.01747532894736842\n",
      "Root Mean Squared Error: 0.13219428485138238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkras\\anaconda3\\envs\\MachineL\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TypeA    2503\n",
       "TypeB     200\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a predict function that uses KNN to predict the output column in test_data\n",
    "#then write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "def predict_knn(test_data):\n",
    "    #split the data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['id'], axis=1), train_data['output'], test_size=0.2, random_state=2)\n",
    "    sScalar = StandardScaler()\n",
    "    X_train = sScalar.fit_transform(X_train)\n",
    "    X_test = sScalar.transform(X_test)\n",
    "    \n",
    "    #create a KNN model\n",
    "    clf = KNeighborsClassifier(n_neighbors=4, p =2 )\n",
    "    #fit the model to the training data\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    #predict the output column in test_data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #test the accuracy of the model\n",
    "    print(\"accuracy score: \",accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # variance score: 1 means perfect prediction\n",
    "    print('Variance score: {}'.format(clf.score(X_test, y_test)))  \n",
    "\n",
    "    #print out the error rates\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    test_data['output'] = 0 \n",
    "    #run the predictions on the test_data\n",
    "    test_data['output'] = clf.predict(test_data.drop(['id'], axis=1))\n",
    "    #round the test_data['output'] to nearest 1 or 0\n",
    "    test_data['output'] = test_data['output'].map({1:'TypeA', 0:'TypeB'})\n",
    "    test_data.to_csv('testdata.txt', sep=',', header=True, index=False)\n",
    "    #drop all the columns except id and output\n",
    "    output_data = test_data[['id','output']]\n",
    "    #write the predictions to a txt file\n",
    "    output_data.to_csv('predictions.txt', sep=',', header=True, index=False)\n",
    "    return test_data, output_data\n",
    "\n",
    "#call the function predict_knn()\n",
    "test_data, output_data = predict_knn(test_data)\n",
    "output_data['output'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN with k =  1 :  0.8447779605263158\n",
      "KNN with k =  2 :  0.7962582236842105\n",
      "KNN with k =  3 :  0.8813733552631579\n",
      "KNN with k =  4 :  0.8694490131578947\n",
      "KNN with k =  5 :  0.8916529605263158\n",
      "KNN with k =  6 :  0.887952302631579\n",
      "KNN with k =  7 :  0.8943256578947368\n",
      "KNN with k =  8 :  0.8955592105263158\n",
      "KNN with k =  9 :  0.8955592105263158\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create a function to cross validate the model\n",
    "def cross_validate(train_data):\n",
    "    #split the data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['id','output'], axis=1), train_data['output'], test_size=0.2, random_state=2)\n",
    "    sScalar = StandardScaler()\n",
    "    X_train = sScalar.fit_transform(X_train)\n",
    "    X_test = sScalar.transform(X_test)\n",
    "    #create a list of the KNN model with different values of K\n",
    "    K = range(1,10)\n",
    "    #create an empty list to store the scores of the KNN model with different values of K\n",
    "    scores = []\n",
    "    #loop through each value of K\n",
    "    for k in K:\n",
    "        #create a KNN model\n",
    "        clf = KNeighborsClassifier(n_neighbors=k)\n",
    "        #fit the model to the training data\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        #append the scores of the model to scores\n",
    "        scores.append(clf.score(X_test, y_test))\n",
    "        print(\"KNN with k = \",k,\": \",scores[k-1])\n",
    "    #plot the scores of the KNN model with different values of K\n",
    "    plt.figure()\n",
    "    plt.plot(K, scores, 'bx-')\n",
    "cross_validate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000000e+00 -1.32267426e-15  1.00000000e+00 ... -1.05688955e-15\n",
      "  1.00000000e+00  1.00000000e+00]\n",
      "accuracy score:  1.0\n",
      "Variance score: 1.0\n",
      "Mean Absolute Error: 5.351063887617677e-16\n",
      "Mean Squared Error: 5.426076087615858e-31\n",
      "Root Mean Squared Error: 7.366190390979491e-16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TypeB    2703\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#create a function that uses linear regression to predict the output column in test_data\n",
    "#then write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "def predict(test_data):\n",
    "    #split the data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['id','output'], axis=1), train_data['output'], test_size=0.35, random_state=4)\n",
    "    #create a linear regression model\n",
    "    regr = linear_model.LinearRegression()\n",
    "    #fit the model to the training data\n",
    "    regr.fit(X_train, y_train)\n",
    "    #predict the output column in test_data\n",
    "    y_pred = regr.predict(X_test)\n",
    "    print(y_pred)\n",
    "    #test the accuracy of the model\n",
    "    print(\"accuracy score: \",accuracy_score(y_test, y_pred.round()))\n",
    "\n",
    "    # variance score: 1 means perfect prediction\n",
    "    print('Variance score: {}'.format(regr.score(X_test, y_test)))  \n",
    "\n",
    "    #print out the error rates\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "    #write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "    test_data['output'] = regr.predict(test_data.drop(['id','output'], axis=1)).round()\n",
    "    #round the test_data['output'] to nearest 1 or 0\n",
    "    test_data['output'] = test_data['output'].map({1:'TypeA', 0:'TypeB'})\n",
    "    test_data.to_csv('testdata.txt', sep=',', header=True, index=False)\n",
    "    #drop all the columns except id and output\n",
    "    output_data = test_data[['id','output']]\n",
    "    #write the predictions to a txt file\n",
    "    output_data.to_csv('predictions.txt', sep=',', header=True, index=False)\n",
    "\n",
    "    return test_data, output_data\n",
    "test_data, output_data = predict(test_data)\n",
    "output_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.8325892857142857\n",
      "Variance score: 0.8325892857142857\n",
      "Mean Absolute Error: 0.16741071428571427\n",
      "Mean Squared Error: 0.16741071428571427\n",
      "Root Mean Squared Error: 0.4091585441924857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TypeA    2374\n",
       "TypeB     329\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a predict function that uses decision tree to predict the output column in test_data\n",
    "#then write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "def predict_tree(test_data):\n",
    "    #split the data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['id','output'], axis=1), train_data['output'], test_size=0.35, random_state=4)\n",
    "    #create a decision tree model\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    #fit the model to the training data\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    #predict the output column in test_data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #test the accuracy of the model\n",
    "    print(\"accuracy score: \",accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # variance score: 1 means perfect prediction\n",
    "    print('Variance score: {}'.format(clf.score(X_test, y_test)))  \n",
    "\n",
    "    #print out the error rates\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "    #write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "    test_data['output'] = clf.predict(test_data.drop(['id','output'], axis=1))\n",
    "    #round the test_data['output'] to nearest 1 or 0\n",
    "    test_data['output'] = test_data['output'].map({1:'TypeA', 0:'TypeB'})\n",
    "    test_data.to_csv('testdata.txt', sep=',', header=True, index=False)\n",
    "    #drop all the columns except id and output\n",
    "    output_data = test_data[['id','output']]\n",
    "    #write the predictions to a txt file\n",
    "    output_data.to_csv('predictions.txt', sep=',', header=True, index=False)\n",
    "    return test_data, output_data\n",
    "\n",
    "#call the function predict()\n",
    "test_data, output_data = predict_tree(test_data)\n",
    "output_data['output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.8955592105263158\n",
      "Variance score: 0.8955592105263158\n",
      "Mean Absolute Error: 0.10444078947368421\n",
      "Mean Squared Error: 0.10444078947368421\n",
      "Root Mean Squared Error: 0.323173002389872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TypeA    2604\n",
       "TypeB      99\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a predict function that uses random forest to predict the output column in test_data\n",
    "#then write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "def predict_forest(test_data):\n",
    "    #split the data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['id','output'], axis=1), train_data['output'], test_size=0.35, random_state=4)\n",
    "    #create a random forest model\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    #fit the model to the training data\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    #predict the output column in test_data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #test the accuracy of the model\n",
    "    print(\"accuracy score: \",accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # variance score: 1 means perfect prediction\n",
    "    print('Variance score: {}'.format(clf.score(X_test, y_test)))  \n",
    "\n",
    "    #print out the error rates\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "    #write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "    test_data['output'] = clf.predict(test_data.drop(['id','output'], axis=1))\n",
    "    #round the test_data['output'] to nearest 1 or 0\n",
    "    test_data['output'] = test_data['output'].map({1:'TypeA', 0:'TypeB'})\n",
    "    test_data.to_csv('testdata.txt', sep=',', header=True, index=False)\n",
    "    #drop all the columns except id and output\n",
    "    output_data = test_data[['id','output']]\n",
    "    #write the predictions to a txt file\n",
    "    output_data.to_csv('predictions.txt', sep=',', header=True, index=False)\n",
    "    return test_data, output_data\n",
    "#call the function predict_forest()\n",
    "test_data, output_data = predict_forest(test_data)\n",
    "output_data['output'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.8612546992481203\n",
      "Variance score: 0.8612546992481203\n",
      "Mean Absolute Error: 0.13874530075187969\n",
      "Mean Squared Error: 0.13874530075187969\n",
      "Root Mean Squared Error: 0.3724853027327114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TypeA    2385\n",
       "TypeB     318\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a predict function that uses Naive Bayes to predict the output column in test_data\n",
    "#then write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "def predict_nb(test_data):\n",
    "    #split the data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['id','output'], axis=1), train_data['output'], test_size=0.35, random_state=4)\n",
    "    #create a naive bayes model\n",
    "    clf = GaussianNB()\n",
    "    #fit the model to the training data\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    #predict the output column in test_data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #test the accuracy of the model\n",
    "    print(\"accuracy score: \",accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # variance score: 1 means perfect prediction\n",
    "    print('Variance score: {}'.format(clf.score(X_test, y_test)))  \n",
    "\n",
    "    #print out the error rates\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "    #write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "    test_data['output'] = 0 \n",
    "    test_data['output'] = clf.predict(test_data.drop(['id','output'], axis=1))\n",
    "    #round the test_data['output'] to nearest 1 or 0\n",
    "    test_data['output'] = test_data['output'].map({1:'TypeA', 0:'TypeB'})\n",
    "    test_data.to_csv('testdata.txt', sep=',', header=True, index=False)\n",
    "    #drop all the columns except id and output\n",
    "    output_data = test_data[['id','output']]\n",
    "    #write the predictions to a txt file\n",
    "    output_data.to_csv('predictions.txt', sep=',', header=True, index=False)\n",
    "    return test_data, output_data\n",
    "\n",
    "#call the function predict_nb()\n",
    "test_data, output_data = predict_nb(test_data)\n",
    "output_data['output'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6c3902b1aa4cde15cc03912761b672b2382cc5d8b5cce935e21b7922c23d74a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('MachineL': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
