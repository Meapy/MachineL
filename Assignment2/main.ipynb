{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import tree \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.float_format',lambda x: '%.4f' %x)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "train_data = pd.read_csv('data/trainingset.txt',header=None)\n",
    "test_data = pd.read_csv('data/queries.txt',header=None)\n",
    "#set column names for train_data\n",
    "train_data.columns = ['id','age','job','marital','education','default','balance','housing','loan','contact','day','month','duration','campaign','pdays','previous','poutcome','output']\n",
    "test_data.columns = ['id','age','job','marital','education','default','balance','housing','loan','contact','day','month','duration','campaign','pdays','previous','poutcome','output']\n",
    "\n",
    "#assign the datatypes to the columns\n",
    "train_data.age = train_data.age.astype('int64')\n",
    "train_data.job = train_data.job.astype('category')\n",
    "train_data.marital = train_data.marital.astype('category')\n",
    "train_data.education = train_data.education.astype('category')\n",
    "train_data.default = train_data.default.map({'yes':1,'no':0})\n",
    "train_data.balance = train_data.balance.astype('float64')\n",
    "train_data.housing = train_data.housing.map({'yes': 1, 'no': 0})\n",
    "train_data.loan = train_data.loan.map({'yes': 1, 'no': 0})\n",
    "train_data.contact = train_data.contact.map({'cellular': 0, 'telephone': 1, 'unknown': 2})\n",
    "train_data.day = train_data.day.astype('int64')\n",
    "train_data.month = train_data.month.astype('category')\n",
    "train_data.duration = train_data.duration.astype('int64')\n",
    "train_data.campaign = train_data.campaign.astype('int64')\n",
    "train_data.pdays = train_data.pdays.astype('int64')\n",
    "train_data.previous = train_data.previous.astype('int64')\n",
    "train_data.poutcome = train_data.poutcome.map({'failure': 0, 'success': 1, 'unknown': 2})\n",
    "train_data.output = train_data.output.map({'TypeA': 1, 'TypeB': 0})\n",
    "\n",
    "#assign the same datatypes to the columns of the test_data\n",
    "test_data.age = test_data.age.astype('int64')\n",
    "test_data.job = test_data.job.astype('category')\n",
    "test_data.marital = test_data.marital.astype('category')\n",
    "test_data.education = test_data.education.astype('category')\n",
    "test_data.default = test_data.default.map({'yes':1,'no':0})\n",
    "test_data.balance = test_data.balance.astype('float64')\n",
    "test_data.housing = test_data.housing.map({'yes': 1, 'no': 0})\n",
    "test_data.loan = test_data.loan.map({'yes': 1, 'no': 0})\n",
    "test_data.contact = test_data.contact.map({'cellular': 0, 'telephone': 1, 'unknown': 2})\n",
    "test_data.day = test_data.day.astype('int64')\n",
    "test_data.month = test_data.month.astype('category')\n",
    "test_data.duration = test_data.duration.astype('int64')\n",
    "test_data.campaign = test_data.campaign.astype('int64')\n",
    "test_data.pdays = test_data.pdays.astype('int64')\n",
    "test_data.previous = test_data.previous.astype('int64')\n",
    "test_data.poutcome = test_data.poutcome.map({'failure': 0, 'success': 1, 'unknown': 2})\n",
    "test_data.output = test_data.output.map({'TypeA': 1, 'TypeB': 0})\n",
    "\n",
    "#convert the catagorical variables to dummy variables\n",
    "train_data = pd.get_dummies(train_data, columns=['job','marital','education','default','housing','loan','contact','month','poutcome'],drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=['job','marital','education','default','housing','loan','contact','month','poutcome'],drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.9825246710526315\n",
      "Variance score: 0.9825246710526315\n",
      "Mean Absolute Error: 0.01747532894736842\n",
      "Mean Squared Error: 0.01747532894736842\n",
      "Root Mean Squared Error: 0.13219428485138238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkras\\anaconda3\\envs\\MachineL\\lib\\site-packages\\sklearn\\base.py:438: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TypeA    2503\n",
       "TypeB     200\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a predict function that uses KNN to predict the output column in test_data\n",
    "#then write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "def predict_knn(test_data):\n",
    "    #split the data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['id'], axis=1), train_data['output'], test_size=0.2, random_state=2)\n",
    "    sScalar = StandardScaler()\n",
    "    X_train = sScalar.fit_transform(X_train)\n",
    "    X_test = sScalar.transform(X_test)\n",
    "    \n",
    "    #create a KNN model\n",
    "    clf = KNeighborsClassifier(n_neighbors=4, p =2 )\n",
    "    #fit the model to the training data\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    #predict the output column in test_data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #test the accuracy of the model\n",
    "    print(\"accuracy score: \",accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # variance score: 1 means perfect prediction\n",
    "    print('Variance score: {}'.format(clf.score(X_test, y_test)))  \n",
    "\n",
    "    #print out the error rates\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "    #set all the values of test_data[output] to 0\n",
    "    test_data['output'] = 0\n",
    "    #run the predictions on the test_data\n",
    "    test_data['output'] = clf.predict(test_data.drop(['id'], axis=1))\n",
    "    #round the test_data['output'] to nearest 1 or 0\n",
    "    test_data['output'] = test_data['output'].map({1:'TypeA', 0:'TypeB'})\n",
    "    test_data.to_csv('testdata.txt', sep=',', header=True, index=False)\n",
    "    #drop all the columns except id and output\n",
    "    output_data = test_data[['id','output']]\n",
    "    #write the predictions to a txt file\n",
    "    output_data.to_csv('predictions.txt', sep=',', header=True, index=False)\n",
    "    return test_data, output_data\n",
    "\n",
    "#call the function predict_knn()\n",
    "test_data, output_data = predict_knn(test_data)\n",
    "output_data['output'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN with k =  1 :  0.9835526315789473\n",
      "KNN with k =  2 :  0.9837582236842105\n",
      "KNN with k =  3 :  0.9806743421052632\n",
      "KNN with k =  4 :  0.9825246710526315\n",
      "KNN with k =  5 :  0.9775904605263158\n",
      "KNN with k =  6 :  0.98046875\n",
      "KNN with k =  7 :  0.9765625\n",
      "KNN with k =  8 :  0.9788240131578947\n",
      "KNN with k =  9 :  0.9747121710526315\n",
      "KNN with k =  10 :  0.9749177631578947\n",
      "KNN with k =  11 :  0.9722450657894737\n",
      "KNN with k =  12 :  0.9720394736842105\n",
      "KNN with k =  13 :  0.9712171052631579\n",
      "KNN with k =  14 :  0.9716282894736842\n",
      "KNN with k =  15 :  0.9693667763157895\n",
      "KNN with k =  16 :  0.9708059210526315\n",
      "KNN with k =  17 :  0.9679276315789473\n",
      "KNN with k =  18 :  0.9689555921052632\n",
      "KNN with k =  19 :  0.9666940789473685\n",
      "KNN with k =  20 :  0.9685444078947368\n",
      "KNN with k =  21 :  0.9668996710526315\n",
      "KNN with k =  22 :  0.967516447368421\n",
      "KNN with k =  23 :  0.9654605263157895\n",
      "KNN with k =  24 :  0.9662828947368421\n",
      "KNN with k =  25 :  0.9640213815789473\n",
      "KNN with k =  26 :  0.9662828947368421\n",
      "KNN with k =  27 :  0.9615542763157895\n",
      "KNN with k =  28 :  0.9631990131578947\n",
      "KNN with k =  29 :  0.9584703947368421\n",
      "KNN with k =  30 :  0.9615542763157895\n",
      "KNN with k =  31 :  0.9576480263157895\n",
      "KNN with k =  32 :  0.9588815789473685\n",
      "KNN with k =  33 :  0.9562088815789473\n",
      "KNN with k =  34 :  0.958264802631579\n",
      "KNN with k =  35 :  0.9576480263157895\n",
      "KNN with k =  36 :  0.9578536184210527\n",
      "KNN with k =  37 :  0.9562088815789473\n",
      "KNN with k =  38 :  0.95703125\n",
      "KNN with k =  39 :  0.9555921052631579\n",
      "KNN with k =  40 :  0.955797697368421\n",
      "KNN with k =  41 :  0.9547697368421053\n",
      "KNN with k =  42 :  0.9555921052631579\n",
      "KNN with k =  43 :  0.9539473684210527\n",
      "KNN with k =  44 :  0.9545641447368421\n",
      "KNN with k =  45 :  0.9537417763157895\n",
      "KNN with k =  46 :  0.9541529605263158\n",
      "KNN with k =  47 :  0.9512746710526315\n",
      "KNN with k =  48 :  0.9514802631578947\n",
      "KNN with k =  49 :  0.9486019736842105\n",
      "KNN with k =  50 :  0.9500411184210527\n",
      "KNN with k =  51 :  0.9473684210526315\n",
      "KNN with k =  52 :  0.9481907894736842\n",
      "KNN with k =  53 :  0.9463404605263158\n",
      "KNN with k =  54 :  0.9471628289473685\n",
      "KNN with k =  55 :  0.9438733552631579\n",
      "KNN with k =  56 :  0.9444901315789473\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_42772/2000478146.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bx-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_42772/2000478146.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(train_data)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#append the scores of the model to scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"KNN with k = \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\": \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#plot the scores of the KNN model with different values of K\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachineL\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachineL\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \"\"\"\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachineL\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    747\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m             chunked_results = list(\n\u001b[0m\u001b[0;32m    750\u001b[0m                 pairwise_distances_chunked(\n\u001b[0;32m    751\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachineL\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1720\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1721\u001b[1;33m             \u001b[0mD_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1722\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1723\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachineL\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_kneighbors_reduce_func\u001b[1;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \"\"\"\n\u001b[0;32m    630\u001b[0m         \u001b[0msample_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m         \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m         \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneigh_ind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;31m# argpartition doesn't guarantee sorted order, so we sort again\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margpartition\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachineL\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m     \"\"\"\n\u001b[1;32m--> 839\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argpartition'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachineL\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#create a function to cross validate the model\n",
    "def cross_validate(train_data):\n",
    "    #split the data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['id'], axis=1), train_data['output'], test_size=0.2, random_state=2)\n",
    "    sScalar = StandardScaler()\n",
    "    X_train = sScalar.fit_transform(X_train)\n",
    "    X_test = sScalar.transform(X_test)\n",
    "    #create a list of the KNN model with different values of K\n",
    "    K = range(1,100)\n",
    "    #create an empty list to store the scores of the KNN model with different values of K\n",
    "    scores = []\n",
    "    #loop through each value of K\n",
    "    for k in K:\n",
    "        #create a KNN model\n",
    "        clf = KNeighborsClassifier(n_neighbors=k)\n",
    "        #fit the model to the training data\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        #append the scores of the model to scores\n",
    "        scores.append(clf.score(X_test, y_test))\n",
    "        print(\"KNN with k = \",k,\": \",scores[k-1])\n",
    "    #plot the scores of the KNN model with different values of K\n",
    "    plt.figure()\n",
    "    plt.plot(K, scores, 'bx-')\n",
    "cross_validate(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84391735 0.8595865  0.44375889 ... 0.93863874 0.95455155 0.88418637]\n",
      "accuracy score:  0.8966165413533834\n",
      "Variance score: 0.18199210785877262\n",
      "Mean Absolute Error: 0.1719665548561169\n",
      "Mean Squared Error: 0.08473701104471518\n",
      "Root Mean Squared Error: 0.2910962229997414\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2703</td>\n",
       "      <td>2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2703</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>TEST1</td>\n",
       "      <td>TypeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id output\n",
       "count    2703   2703\n",
       "unique   2703      2\n",
       "top     TEST1  TypeA\n",
       "freq        1   2625"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#create a function that uses linear regression to predict the output column in test_data\n",
    "#then write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "def predict(test_data):\n",
    "    #split the data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['id','output'], axis=1), train_data['output'], test_size=0.35, random_state=4)\n",
    "    #create a linear regression model\n",
    "    regr = linear_model.LinearRegression()\n",
    "    #fit the model to the training data\n",
    "    regr.fit(X_train, y_train)\n",
    "    #predict the output column in test_data\n",
    "    y_pred = regr.predict(X_test)\n",
    "    print(y_pred)\n",
    "    #test the accuracy of the model\n",
    "    print(\"accuracy score: \",accuracy_score(y_test, y_pred.round()))\n",
    "\n",
    "    # variance score: 1 means perfect prediction\n",
    "    print('Variance score: {}'.format(regr.score(X_test, y_test)))  \n",
    "\n",
    "    #print out the error rates\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "    #write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "    test_data['output'] = regr.predict(test_data.drop(['id','output'], axis=1)).round()\n",
    "    #round the test_data['output'] to nearest 1 or 0\n",
    "    test_data['output'] = test_data['output'].map({1:'TypeA', 0:'TypeB'})\n",
    "    test_data.to_csv('testdata.txt', sep=',', header=True, index=False)\n",
    "    #drop all the columns except id and output\n",
    "    output_data = test_data[['id','output']]\n",
    "    #write the predictions to a txt file\n",
    "    output_data.to_csv('predictions.txt', sep=',', header=True, index=False)\n",
    "\n",
    "    return test_data, output_data\n",
    "test_data, output_data = predict(test_data)\n",
    "output_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.8344689849624061\n",
      "Variance score: 0.8344689849624061\n",
      "Mean Absolute Error: 0.165531015037594\n",
      "Mean Squared Error: 0.165531015037594\n",
      "Root Mean Squared Error: 0.4068550295100135\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2703</td>\n",
       "      <td>2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2703</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>TEST1</td>\n",
       "      <td>TypeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id output\n",
       "count    2703   2703\n",
       "unique   2703      2\n",
       "top     TEST1  TypeA\n",
       "freq        1   2376"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a predict function that uses decision tree to predict the output column in test_data\n",
    "#then write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "def predict_tree(test_data):\n",
    "    #split the data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['id','output'], axis=1), train_data['output'], test_size=0.35, random_state=4)\n",
    "    #create a decision tree model\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    #fit the model to the training data\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    #predict the output column in test_data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #test the accuracy of the model\n",
    "    print(\"accuracy score: \",accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # variance score: 1 means perfect prediction\n",
    "    print('Variance score: {}'.format(clf.score(X_test, y_test)))  \n",
    "\n",
    "    #print out the error rates\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "    #write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "    test_data['output'] = clf.predict(test_data.drop(['id','output'], axis=1))\n",
    "    #round the test_data['output'] to nearest 1 or 0\n",
    "    test_data['output'] = test_data['output'].map({1:'TypeA', 0:'TypeB'})\n",
    "    test_data.to_csv('testdata.txt', sep=',', header=True, index=False)\n",
    "    #drop all the columns except id and output\n",
    "    output_data = test_data[['id','output']]\n",
    "    #write the predictions to a txt file\n",
    "    output_data.to_csv('predictions.txt', sep=',', header=True, index=False)\n",
    "    return test_data, output_data\n",
    "\n",
    "#call the function predict()\n",
    "test_data, output_data = predict_tree(test_data)\n",
    "output_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.8953242481203008\n",
      "Variance score: 0.8953242481203008\n",
      "Mean Absolute Error: 0.10467575187969924\n",
      "Mean Squared Error: 0.10467575187969924\n",
      "Root Mean Squared Error: 0.3235363223499013\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2703</td>\n",
       "      <td>2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2703</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>TEST1</td>\n",
       "      <td>TypeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id output\n",
       "count    2703   2703\n",
       "unique   2703      2\n",
       "top     TEST1  TypeA\n",
       "freq        1   2616"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a predict function that uses random forest to predict the output column in test_data\n",
    "#then write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "def predict_forest(test_data):\n",
    "    #split the data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['id','output'], axis=1), train_data['output'], test_size=0.35, random_state=4)\n",
    "    #create a random forest model\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    #fit the model to the training data\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    #predict the output column in test_data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #test the accuracy of the model\n",
    "    print(\"accuracy score: \",accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # variance score: 1 means perfect prediction\n",
    "    print('Variance score: {}'.format(clf.score(X_test, y_test)))  \n",
    "\n",
    "    #print out the error rates\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "    #write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "    test_data['output'] = clf.predict(test_data.drop(['id','output'], axis=1))\n",
    "    #round the test_data['output'] to nearest 1 or 0\n",
    "    test_data['output'] = test_data['output'].map({1:'TypeA', 0:'TypeB'})\n",
    "    test_data.to_csv('testdata.txt', sep=',', header=True, index=False)\n",
    "    #drop all the columns except id and output\n",
    "    output_data = test_data[['id','output']]\n",
    "    #write the predictions to a txt file\n",
    "    output_data.to_csv('predictions.txt', sep=',', header=True, index=False)\n",
    "    return test_data, output_data\n",
    "#call the function predict_forest()\n",
    "test_data, output_data = predict_forest(test_data)\n",
    "output_data.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.8612546992481203\n",
      "Variance score: 0.8612546992481203\n",
      "Mean Absolute Error: 0.13874530075187969\n",
      "Mean Squared Error: 0.13874530075187969\n",
      "Root Mean Squared Error: 0.3724853027327114\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2703</td>\n",
       "      <td>2703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2703</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>TEST1</td>\n",
       "      <td>TypeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id output\n",
       "count    2703   2703\n",
       "unique   2703      2\n",
       "top     TEST1  TypeA\n",
       "freq        1   2385"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a predict function that uses Naive Bayes to predict the output column in test_data\n",
    "#then write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "def predict_nb(test_data):\n",
    "    #split the data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['id','output'], axis=1), train_data['output'], test_size=0.35, random_state=4)\n",
    "    #create a naive bayes model\n",
    "    clf = GaussianNB()\n",
    "    #fit the model to the training data\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    #predict the output column in test_data\n",
    "    y_pred = clf.predict(X_test)\n",
    "    #test the accuracy of the model\n",
    "    print(\"accuracy score: \",accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # variance score: 1 means perfect prediction\n",
    "    print('Variance score: {}'.format(clf.score(X_test, y_test)))  \n",
    "\n",
    "    #print out the error rates\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "    #write the predictions to a txt file using the layout <id>,<output> where <id> is the id and <output> is either TypeA or TypeB\n",
    "    test_data['output'] = clf.predict(test_data.drop(['id','output'], axis=1))\n",
    "    #round the test_data['output'] to nearest 1 or 0\n",
    "    test_data['output'] = test_data['output'].map({1:'TypeA', 0:'TypeB'})\n",
    "    test_data.to_csv('testdata.txt', sep=',', header=True, index=False)\n",
    "    #drop all the columns except id and output\n",
    "    output_data = test_data[['id','output']]\n",
    "    #write the predictions to a txt file\n",
    "    output_data.to_csv('predictions.txt', sep=',', header=True, index=False)\n",
    "    return test_data, output_data\n",
    "\n",
    "#call the function predict_nb()\n",
    "test_data, output_data = predict_nb(test_data)\n",
    "output_data.describe()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6c3902b1aa4cde15cc03912761b672b2382cc5d8b5cce935e21b7922c23d74a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('MachineL': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
